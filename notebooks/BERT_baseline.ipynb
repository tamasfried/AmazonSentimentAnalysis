{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21449baf",
   "metadata": {},
   "source": [
    "# Transformer-based baseline (BERT)\n",
    "\n",
    "A transformer-based sentiment classification model is evaluated using a pre-trained BERT architecture. This notebook establishes a deep learning baseline to compare against classical machine learning approaches based on TF-IDF features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a51c7",
   "metadata": {},
   "source": [
    "## Load dataset and create train–test split\n",
    "\n",
    "The same cleaned and balanced review dataset used for the classical machine learning baselines is loaded. The train–test split is reproduced to ensure a fair comparison between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c687085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/balanced_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7731d89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fd1bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and labels\n",
    "X = df[\"Text\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# Create a reproducible train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057dcb4",
   "metadata": {},
   "source": [
    "## Tokenisation using a pre-trained BERT tokenizer\n",
    "Text data is converted into tokens that the BERT model can understand. This step prepares the text for input into the BERT model by converting words into numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00de80a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tommorton/Library/CloudStorage/OneDrive-Personal/Masters/Comp Sci/Modules/Masters Project/AmazonSentinmentAnalysis/notebooks/.hf_cache'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set a local Hugging Face cache directory inside the project\n",
    "os.environ[\"HF_HOME\"] = os.path.join(os.getcwd(), \".hf_cache\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(os.getcwd(), \".hf_cache\")\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f74f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    cache_dir=os.path.join(os.getcwd(), \".hf_cache\")\n",
    ")\n",
    "\n",
    "# Tokenise the training and test sets\n",
    "train_encodings = tokenizer(\n",
    "    X_train.tolist(), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=128\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    X_test.tolist(),\n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89545da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
